---
title: "Organize Data Notebook"
---

```{r}
#| label: setup
#| include: false
library(here)
source(here("utils","check_packages.R"))
source(here("utils","functions.R"))
```

# Introduction

This notebook documents the process of reading American Community Survey data from [IPUMS](https://ipums.org) and converting it to a set of "marriage market" data that can be used to model marriage choices, using the [fakeunion](https://github.com/AaronGullickson/fakeunion) package. To do that I need three datasets:

1. A dataset of actual recent marriages with symmetrical information about each spouse. I am only looking at opposite-sex unions for this analysis.
2. A dataset of potential male partners that is made up of those recently married (from 1) and currently single people (those not in cohabitation or less recent marriages). This dataset should contain all the same information about these men as the husbands from (1).
3. A dataset identical to (2) but for potential female partners.

I set up a few key parameters right at the top of the document

```{r}
#| label: set-params
years_mar <- 5  # limit on the duration of marriages that will be identified
n_samples <- 2  # number of separate marriage markets to construct
n_fakes   <- 5  # number of fake unions to generate for each real one
```

Next, I set up several functions that will be useful for coding the data. Since I have to repeat the same coding for several variables on both partners in a union, it makes sense to put that coding into a function to minimize code and the risk of error.

```{r}
#| label: coding-functions

# since I have to code the same variable for both spouses, it makes sense to put
# this coding into a function

code_race <- function(raced, hispand) {
  # We want to take the raced and hispand variables and code them into a combined
  # race variable. I am going to use the fullest possible coding here. 
  race <- case_when(
    # Latino trumps everything, because combined question, sigh
    hispand>0 & hispand<900 ~ "Latino",
    # white and black are easy
    raced==100 ~ "White",
    raced==200 ~ "Black",
    # for indigenous we get all AIAN, Pacific Islanders, and the one multiracial
    # combo of them (855)
    (raced>=300 & raced<400) | (raced==630 | (raced>=680 & raced<=699)) | 
      raced==855 ~ "Indigenous",
    # Asian - also need to grab a couple of multiracial response which are 
    # really multiethnic Asian
    ((raced>=400 & raced<=679) | raced %in% c(869, 887)) ~ "Asian",
    # Biracial groups
    raced==801 ~ "White/Black",
    (raced>=810 & raced<=819) ~ "White/Asian",
    (raced>=831 & raced<=838) ~ "Black/Asian",
    # for all part Indigenous groups we need to get the part AIAN and part PI
    raced==802 | (raced>=820 & raced<=825) ~ "White/Indigenous",
    raced==830 | (raced>=840 & raced<=842) ~ "Black/Indigenous",
    (raced>=850 & raced<=854) | (raced>=860 & raced<=868) ~ "Indigenous/Asian",
    TRUE ~ NA_character_
  )
  
  race <- factor(race, 
                 levels=c("White","Black","Indigenous","Asian","Latino",
                          "White/Black","White/Indigenous","White/Asian",
                          "Black/Indigenous","Black/Asian","Indigenous/Asian"))
  
  return(race)
}


code_educ <- function(educd) {
  # We want to re-code the educd variable into the following simple
  # categories:
  # - Less than high school diploma
  # - High school diploma
  # - Some college, but less than a four year degree
  # - Four year college degree or more
  educ <- ifelse(educd<60, "LHS",
                 ifelse(educd<=65, "HS",
                        ifelse(educd<=90, "SC",
                               ifelse(educd<=999, "C", 
                                      NA))))
  educ <- factor(educ,
                 levels=c("LHS","HS","SC","C"),
                 ordered=TRUE)
  return(educ)
}

code_bpl <- function(bpld) {
  #recode any one born in the US (99 or less) as a single number. Otherwise
  #we will be fitting state level endogamy. also code in missing values
  
  # The general codes are way to general. The detailed codes have some
  # overspecifity in the codes, but not in the actual data used here.
  return(ifelse(bpld>=95000, NA, 
                ifelse(bpld<10000,1,bpld)))
}

code_language <- function(language) {
  #I need to use the detailed language codes as the general language codes 
  #are too general. However the detailed language codes are too detailed in 
  #some places, particularly in translating between the two time periods. Thus
  #I make some corrections to the detailed codes for consistency between the
  #two time periods.
  
  # We don't need to code language as a factor variable with labels because
  # ultimately all we need to know is whether the two partners speak the same
  # language. We should however code in any missing values (0), although 
  # there do not appear to be any.
  
  lang_recode <- language
  
  #the following cases will be collapsed to the their top two digit codes
  #(starting at the 100 levels)
  #1:27 - European language groups (e.g. English, French, German)
  #35: Uralic
  #37: Other Altaic
  #43: Chinese
  #47: Thai/Siamese/Lao (not separable in 1980)
  #52: Indonesian
  #53: Other Malay
  #58:  Near East Arabic Dialect
  collapsed_cases <- c(1:24,35,37,43,47,52,53,58)
  collapsed_language <- floor(language/100)
  lang_recode <- ifelse(collapsed_language %in% collapsed_cases,
                        collapsed_language*100, lang_recode)
  
  #A couple of cases need to be put back into there other categories
  #420: Afrikaans
  #1140: Haitian Creole
  #1150: Cajun
  #2310: Croatian
  #2320: Serbian
  uncollapsed_cases <- c(420,1140,1150,2310,2320)
  lang_recode <- ifelse(language %in% uncollapsed_cases,
                        language, lang_recode)
  
  #put malay and other malay together
  lang_recode <- ifelse(language==5270, 5300, lang_recode)
  
  #collapse Hindi and Urdu into 3101 (Hindustani)
  lang_recode <- ifelse(language>3101 & language<=3104, 3101, lang_recode)
  
  #For 1980 consistency put all American Indian languages in one group
  lang_recode <- ifelse(lang_recode>7000 & lang_recode<=9300, 7000, 
                        lang_recode)
  
  #A few cases are "other" or "nec". These will be recoded as -1 and
  #not treated as endogamy with each other
  nec_codes <- c(3140,3150,3190,5290,5590,6200,6390,6400,9400,9410,9420,9500,
                 9600,9601,9602,9999)
  lang_recode <- ifelse(lang_recode %in% nec_codes, -1, lang_recode)
  
  #code any missing values 
  lang_recode <- ifelse(lang_recode==0, NA, lang_recode)
  
  return(lang_recode)
  
}

code_generation <- function(bpl, age, year, yr_usa) {
  
  # first, calculate age of entry into the US, NA for all non-migrants
  age_usa <- age-yr_usa
  # check
  #tapply(age_usa, bpl>1, mean)
  #summary(age_usa)
  # some of these responses are as negative as -5. -1 is expected because of
  # the crudeness of calendar year vs birthdays. Almost all of the values 
  # greater than -1 are for year of migration prior to 1940, which is top-coded
  # in the data, so I think those make sense as well. In those cases, we will
  # just replace with zero.
  age_usa <- ifelse(age_usa<0, 0, age_usa)
  
  # now we can code our generations. All native-borns are 2nd+.
  generation <- case_when(
    is.na(bpl) ~ NA_character_,
    bpl==1 ~ "2nd+",
    age_usa<6 ~ "1.75",
    age_usa<13 ~ "1.5",
    age_usa<18 ~ "1.25",
    !is.na(age_usa) ~ "1st"
  )
  
  generation <- factor(generation,
                       levels=c("1st","1.25","1.5","1.75","2nd+"))
    
  # checks
  #summary(generation)
  #table(bpl>1, generation, exclude=NULL)
  #tapply(age_usa, generation, min)
  #tapply(age_usa, generation, max)

  return(generation)
}

```


# Read in the data

The data are ACS data from 2016-2021, extracted via IPUMS. To keep each extract small, I extract each year separately and then combined them together when I read them in. They are fixed-width files identical in structure. Below, I show all variables and their position in the files. This is for 2021, but the structure is identical for all years.

```
  Variable                         Columns        Len   2021    
  YEAR                         H   1-4            4     X       
  SAMPLE                       H   5-10           6     X       
  SERIAL                       H  11-18           8     X       
  CBSERIAL                     H  19-31          13     X       
  HHWT                         H  32-41          10     X       
  CLUSTER                      H  42-54          13     X       
  STATEFIP                     H  55-56           2     X       
  MET2013                      H  57-61           5     X       
  STRATA                       H  62-73          12     X       
  GQ                           H  74              1     X       
  PERNUM                       P  75-78           4     X       
  PERWT                        P  79-88          10     X       
  SEX                          P  89              1     X       
  AGE                          P  90-92           3     X       
  MARST                        P  93              1     X       
  MARRNO                       P  94              1     X       
  YRMARR                       P  95-98           4     X       
  RACE                         P  99              1     X       
  RACED                        P 100-102          3     X       
  HISPAN                       P 103              1     X       
  HISPAND                      P 104-106          3     X       
  BPL                          P 107-109          3     X       
  BPLD                         P 110-114          5     X       
  YRIMMIG                      P 115-118          4     X       
  LANGUAGE                     P 119-120          2     X       
  LANGUAGED                    P 121-124          4     X       
  EDUC                         P 125-126          2     X       
  EDUCD                        P 127-129          3     X       
  PERNUM_SP                    P 130-133          4     X       
  SEX_SP                       P 134              1     X       
  AGE_SP                       P 135-137          3     X       
  RACED_SP                     P 138-140          3     X       
  HISPAND_SP                   P 141-143          3     X       
  BPLD_SP                      P 144-148          5     X       
  YRIMMIG_SP                   P 149-152          4     X       
  LANGUAGED_SP                 P 153-156          4     X       
  EDUCD_SP                     P 157-159          3     X          
```


Below, I create the starting and ending indices as well as the variable names for the variables that I will pull from the fixed-width data. These numbers should correspond to those shown above. I capitalize all variables from the original data to distinguish my constructed variables (always lower case) from variables directly in the original data.

```{r}
#| label: create-cols-info
acs_start <- c(1,11,32,55,57,75,89,90,93,94,95,100,104,110,115,121,127,130,134,135,138,141,144,149,153,157)
acs_end   <- c(4,18,41,56,61,78,89,92,93,94,98,102,106,114,118,124,129,133,134,137,140,143,148,152,156,159)
acs_names <- c("YEAR","SERIAL","HHWT","STATEFIP","METAREA","PERNUM",
               "SEX","AGE","MARST","MARRNO","YRMARR","RACED",
               "HISPAND","BPLD","YRIMMIG","LANGUAGED","EDUCD","PERNUM_SP",
               "SEX_SP","AGE_SP","RACED_SP","HISPAND_SP","BPLD_SP",
               "YRIMMIG_SP","LANGUAGED_SP","EDUCD_SP")
tibble(variable=acs_names, start=acs_start, end=acs_end) |>
  gt()
```




Now, I am ready to read the data in. Because the dataset is very large, the data are currently stored on Google Drive and accessed using the `googledrive` library. A local copy is downloaded, read in, and then deleted. To access the data, you will need to first authenticate with google interactively using `googledrive::drive_auth()`. 



```{r}
#| label: read-data

# where the downloaded data will live (temporarily)
file_path <- here("data","data_raw","acs.dat.gz")

drive_download(as_id("11CsNYkl1AlB2NCW4UCMo1aGyaBTn7Pwz"), path=file_path)

acs <- read_fwf(file_path,
                col_positions = fwf_positions(start = acs_start,
                                              end   = acs_end,
                                              col_names = acs_names),
                col_types = cols(.default = "i", HHWT="d"), 
                progress = FALSE)

# now that the data are loaded, delete
file.remove(file_path)
```

# Code variables

I recode, create, and clean all of the variables that I need in one `mutate` call. Embedded comments should provide more details. I will check my coding below. 

```{r}
#| label: code-variables
acs <- acs |> 
  mutate(
    ## unique ids for each respondent ##
    id = SERIAL*1000000+PERNUM*10000+YEAR,
    id_sp = ifelse(is.na(PERNUM_SP),NA,
                    SERIAL*1000000+PERNUM_SP*10000+YEAR),
    ## sex of respondent and spouse ##
    sex = ifelse(SEX==1, "Male", ifelse(SEX==2, "Female", NA)),
    sex_sp = ifelse(SEX_SP==1, "Male", ifelse(SEX_SP==2, "Female", NA)),
    ## age of respondent and spouse ##
    age=AGE,
    age_sp=AGE_SP,
    ## marital status of respondent ##
    mar_stat=factor(MARST, levels=1:6, 
                    labels=c("Married, spouse present", "Married, spouse absent",
                             "Separated","Divorced","Widowed","Never married")),
    ## race of respondent and spouse - see details in code_race function ##
    race = code_race(RACED, HISPAND),
    race_sp = code_race(RACED_SP, HISPAND_SP),
    ## education of respondent and spouse - see code_educ function for details ##
    educ = code_educ(EDUCD),
    educ_sp = code_educ(EDUCD_SP),
    ## language of respondent and spouse - see code_lang for details ##
    lang = code_language(LANGUAGED),
    lang_sp = code_language(LANGUAGED_SP),
    ## marriage market id ##
    # I am going to do marriage markets by state and year. No need to restrict
    # to metro areas really as the differences are very small and this lets
    # me maximize sample size
    mar_market = paste(STATEFIP, YEAR, sep=""),
    ## marriage duration ##
    dur_mar = ifelse(YRMARR==0, NA, YEAR - YRMARR),
    ## country of birth of respondent and spouse - see code_bpl for details ##
    bpl = code_bpl(BPLD),
    bpl_sp = code_bpl(BPLD_SP),
    ## Years in the USA - missing for natives ##
    yr_usa = ifelse(YRIMMIG==0, NA, YEAR-YRIMMIG),
    yr_usa_sp = ifelse(YRIMMIG_SP==0, NA, YEAR-YRIMMIG_SP),
    ## immigrant generation - see code_generation for details ##
    immig_gen = code_generation(bpl, age, YEAR, yr_usa),
    immig_gen_sp = code_generation(bpl_sp, age_sp, YEAR, yr_usa_sp)
  )
```

Ok, now I check to make sure all of my coding worked as expected. This is a long section because the output is often quite large. 

```{r}
#| label: check-yourself

options(max.print=10000)

# Do we have any duplicates in our ids?
sum(duplicated(acs$id))
sum(duplicated(na.omit(acs$id_sp)))

# check sex
table(acs$sex, acs$SEX, exclude=NULL)
table(acs$sex_sp, acs$SEX_SP, exclude=NULL)

# check mar_stat
table(acs$mar_stat, acs$MARST, exclude=NULL)

# check age
summary(acs$age)
summary(acs$age_sp)

# check educ
table(acs$EDUCD, acs$educ, exclude=NULL)
table(acs$EDUCD_SP, acs$educ_sp, exclude=NULL)

# check race
table(acs$RACED, acs$race, exclude=NULL)
table(acs$HISPAND, acs$race, exclude=NULL)
table(acs$RACED_SP, acs$race_sp, exclude=NULL)
table(acs$HISPAND_SP, acs$race_sp, exclude=NULL)

# check birthplace
summary(acs$bpl)
summary(acs$bpl_sp)

# check language
summary(acs$lang)
sum(acs$lang==-1)
summary(acs$lang_sp)
sum(acs$lang_sp==-1, na.rm=TRUE)

# check dur_mar
summary(acs$dur_mar)

# check immigrant generation
table(acs$bpl>1, acs$immig_gen, exclude=NULL)
table(acs$bpl_sp>1, acs$immig_gen_sp, exclude=NULL)

options(max.print=99999)
```

Everything is coming up green lights at the moment.

# Make restrictions

Now that I have coded and checked the ACS dataset, lets just restrict to the variables that I need to keep things tidy. I will also remove cases that are missing on `race` or `race_sp` because those are individuals who had a race outside of what I am considering here (other single or in combination and more than two races). I will also drop the relatively few cases that were missing birthplace. Dropping on spouse `race_sp` and `bpl_sp` has to first check to make sure its a valid case otherwise (given by a non-missing id).

```{r}
#| label: drop-missing-select-vars
acs <- acs |>
  filter(!is.na(race) & !is.na(bpl)) |>
  filter(is.na(id_sp) | (!is.na(race_sp) & !is.na(bpl_sp))) |>
  select(mar_market, mar_stat, dur_mar, 
         id, sex, age, race, educ, lang, bpl, immig_gen, yr_usa,
         id_sp, sex_sp, age_sp, race_sp, educ_sp, lang_sp, bpl_sp, immig_gen_sp,
         yr_usa_sp)
```

I also want to eliminate individuals from the analysis who:

* have been in the USA less than the marriage window.
* Made an interstate move in the last five years <!-- TODO: implement this -->
* Are currently married longer than the marriage window.
* Are married individuals in same-sex relationships
* Are cohabitors - these are identified by a valid spouse id but not married, spouse present on `mar_stat`

Therefore, the only remaining people in the dataset are heterosexual married couples married for five years or less and single individuals, all of whom have been in the same "marriage market" for the last five years.

```{r}
#| label: restrict-cases
acs <- acs |>
  filter((is.na(yr_usa) | yr_usa>years_mar) & 
           (is.na(yr_usa_sp) | yr_usa_sp>years_mar) &
           ((mar_stat!="Married, spouse present" & 
               mar_stat!="Married, spouse absent") | dur_mar<=years_mar) &
           !(!is.na(sex_sp) & sex==sex_sp) &
           !(mar_stat!="Married, spouse present" & !is.na(id_sp)))

# checks
summary(acs$yr_usa)
summary(acs$yr_usa_sp)
tapply(acs$dur_mar, acs$mar_stat, max)
table(acs$sex, acs$sex_sp, exclude=NULL)
acs |> 
  group_by(mar_stat, !is.na(id_sp)) |>
  summarize(n=n())
```

# Create marriage market data

Now, I am ready to create the union and male/female alternate datasets that I will feed into `fakeunion` to get my marriage market data.

```{r}
#| label: create-groups

# create actual union data
unions <- acs |>
  filter(sex=="Male" & sex_sp=="Female" & !is.na(id_sp) & 
           mar_stat=="Married, spouse present")

# check that they are all hetero
table(unions$sex, unions$sex_sp, exclude=NULL)

# check the marital status 
table(unions$mar_stat)

# check marriage duration
summary(unions$dur_mar)

# check years in the USA is past marriage duration
summary(unions$yr_usa)

# ok now limit it to only necessary variables and rename
unions <- unions |>
  select(mar_market, id, age, race, educ, lang, bpl, immig_gen, 
         id_sp, age_sp, race_sp, educ_sp, lang_sp, bpl_sp, immig_gen_sp) |>
  rename(idh=id, ageh=age, raceh=race, educh=educ, langh=lang, bplh=bpl, 
         immig_genh=immig_gen,
         idw=id_sp, agew=age_sp, racew=race_sp, educw=educ_sp, langw=lang_sp, 
         bplw=bpl_sp, immig_genw=immig_gen_sp) 

# create alternate partner data
female_alt <- acs |>
  filter(sex=="Female") |>
  select(mar_market, id, age, race, educ, lang, bpl, immig_gen) |>
  rename(idw=id, agew=age, racew=race, educw=educ, langw=lang, bplw=bpl,
         immig_genw=immig_gen)

male_alt <- acs |>
  filter(sex=="Male") |>
  select(mar_market, id, age, race, educ, lang, bpl, immig_gen) |>
  rename(idh=id, ageh=age, raceh=race, educh=educ, langh=lang, bplh=bpl,
         immig_genh=immig_gen)
```

Now, that I have these datasets, I can feed them into the `generateCouples` function to create my marriage market data. I use the replicate function to create multiple marriage markets so I can pool results across multiple random imputations of fake partners.

Note that the `generateCouples` data cannot handle tibbles properly so I am casting these back to vanilla data.frames and then re-tibblizing the end product. 

```{r}
#| label: create-fake-unions

# fakeunion does not handle tibbles well so convert to vanilla dfs
mar_markets <- replicate(n_samples,
                         generateCouples(n_fakes, as.data.frame(unions), 
                                         as.data.frame(male_alt), 
                                         as.data.frame(female_alt), 
                                         geo="mar_market", 
                                         verbose=FALSE),
                         simplify=FALSE)

mar_markets <- lapply(mar_markets, as_tibble)
```

Lets do a summary on the first one just to make sure it all looks good.

```{r}
#| label: check-mar-market-data
summary(mar_markets[[1]])
```

It should be all good to go. Lets save it.

```{r}
#| label: save-data
save(mar_markets, file=here("data","data_constructed","markets.RData"))
```