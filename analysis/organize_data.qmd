---
title: "Organize Data Notebook"
---

```{r}
#| label: timestamp-start
timestamp()
```

```{r}
#| label: setup
#| include: false
library(here)
source(here("utils","check_packages.R"))
source(here("utils","functions.R"))
sessionInfo()
```

```{r}
#| label: de-authorize google drive

# this should anyone to access the data
drive_deauth()
```

# Introduction

This notebook documents the process of reading American Community Survey data from [IPUMS](https://ipums.org) and converting it to a set of "marriage market" data that can be used to model marriage choices, using the [fakeunion](https://github.com/AaronGullickson/fakeunion) package. To do that I need three datasets:

1. A dataset of actual recent marriages with symmetrical information about each spouse. I am only looking at opposite-sex unions for this analysis.
2. A dataset of potential male partners that is made up of those recently married (from 1) and currently single people (those not in cohabitation or less recent marriages). This dataset should contain all the same information about these men as the husbands from (1).
3. A dataset identical to (2) but for potential female partners.

I set up a few key parameters right at the top of the document

```{r}
#| label: set-params
set.seed(39)
years_mar <- 5  # limit on the duration of marriages that will be identified
n_samples <- 3  # number of separate marriage markets to construct
n_fakes   <- 7  # number of fake unions to generate for each real one
```

Next, I set up several functions that will be useful for coding the data. Since I have to repeat the same coding for several variables on both partners in a union, it makes sense to put that coding into a function to minimize code and the risk of error.

```{r}
#| label: coding-functions

# since I have to code the same variable for both spouses, it makes sense to put
# this coding into a function

code_race <- function(raced, hispand) {
  # We want to take the raced and hispand variables and code them into a combined
  # race variable. I am going to use the fullest possible coding here. 
  race <- case_when(
    # Latino trumps everything, because combined question, sigh
    # However, we will split them into Latino, Single Race and Latino, 
    # Multiple Race - CORRECTION, we will do this as a sensitivity analysis
    # but its not showing any real differences, so we will leave as one to 
    # simplify main analysis
    #hispand>0 & hispand<900 & raced>=800 ~ "Latino, Multiple Race",
    #hispand>0 & hispand<900 & raced<800 ~ "Latino, Single Race",
    hispand>0 & hispand<900 ~ "Latino",
    # white and black are easy
    raced==100 ~ "White",
    raced==200 ~ "Black",
    # for indigenous we get all AIAN, Pacific Islanders, and the one multiracial
    # combo of them (855)
    (raced>=300 & raced<400) | (raced==630 | (raced>=680 & raced<=699)) | 
      raced==855 ~ "Indigenous",
    # Asian - also need to grab a couple of multiracial response which are 
    # really multiethnic Asian
    ((raced>=400 & raced<=679) | raced %in% c(869, 887)) ~ "Asian",
    # Biracial groups
    raced==801 ~ "White-Black",
    (raced>=810 & raced<=819) ~ "White-Asian",
    (raced>=831 & raced<=838) ~ "Black-Asian",
    # for all part Indigenous groups we need to get the part AIAN and part PI
    raced==802 | (raced>=820 & raced<=825) ~ "White-Indigenous",
    raced==830 | (raced>=840 & raced<=842) ~ "Black-Indigenous",
    (raced>=850 & raced<=854) | (raced>=860 & raced<=868) ~ "Asian-Indigenous",
    TRUE ~ NA_character_
  )
  
  race <- factor(race, 
                 levels=c("White","Black","Indigenous","Asian", "Latino",
                          "White-Black","White-Indigenous","White-Asian",
                          "Black-Indigenous","Black-Asian","Asian-Indigenous"))
  
  return(race)
}


code_educ <- function(educd) {
  # We want to re-code the educd variable into the following simple
  # categories:
  # - Less than high school diploma
  # - High school diploma
  # - Some college, but less than a four year degree
  # - Four year college degree or more
  educ <- ifelse(educd<60, "LHS",
                 ifelse(educd<=65, "HS",
                        ifelse(educd<=90, "SC",
                               ifelse(educd<=999, "C", 
                                      NA))))
  educ <- factor(educ,
                 levels=c("LHS","HS","SC","C"),
                 ordered=TRUE)
  return(educ)
}

code_bpl <- function(bpld) {
  #recode any one born in the US (99 or less) as a single number. Otherwise
  #we will be fitting state level endogamy. also code in missing values
  
  # The general codes are way to general. The detailed codes have some
  # overspecifity in the codes, but not in the actual data used here.
  return(ifelse(bpld>=95000, NA, 
                ifelse(bpld<10000,1,bpld)))
}

code_language <- function(language) {
  #I need to use the detailed language codes as the general language codes 
  #are too general. However the detailed language codes are too detailed in 
  #some places, particularly in translating between the two time periods. Thus
  #I make some corrections to the detailed codes for consistency between the
  #two time periods.
  
  # We don't need to code language as a factor variable with labels because
  # ultimately all we need to know is whether the two partners speak the same
  # language. We should however code in any missing values (0), although 
  # there do not appear to be any.
  
  lang_recode <- language
  
  #the following cases will be collapsed to the their top two digit codes
  #(starting at the 100 levels)
  #1:27 - European language groups (e.g. English, French, German)
  #35: Uralic
  #37: Other Altaic
  #43: Chinese
  #47: Thai/Siamese/Lao (not separable in 1980)
  #52: Indonesian
  #53: Other Malay
  #58:  Near East Arabic Dialect
  collapsed_cases <- c(1:24,35,37,43,47,52,53,58)
  collapsed_language <- floor(language/100)
  lang_recode <- ifelse(collapsed_language %in% collapsed_cases,
                        collapsed_language*100, lang_recode)
  
  #A couple of cases need to be put back into there other categories
  #420: Afrikaans
  #1140: Haitian Creole
  #1150: Cajun
  #2310: Croatian
  #2320: Serbian
  uncollapsed_cases <- c(420,1140,1150,2310,2320)
  lang_recode <- ifelse(language %in% uncollapsed_cases,
                        language, lang_recode)
  
  #put malay and other malay together
  lang_recode <- ifelse(language==5270, 5300, lang_recode)
  
  #collapse Hindi and Urdu into 3101 (Hindustani)
  lang_recode <- ifelse(language>3101 & language<=3104, 3101, lang_recode)
  
  #For 1980 consistency put all American Indian languages in one group
  lang_recode <- ifelse(lang_recode>7000 & lang_recode<=9300, 7000, 
                        lang_recode)
  
  #A few cases are "other" or "nec". These will be recoded as -1 and
  #not treated as endogamy with each other
  nec_codes <- c(3140,3150,3190,5290,5590,6200,6390,6400,9400,9410,9420,9500,
                 9600,9601,9602,9999)
  lang_recode <- ifelse(lang_recode %in% nec_codes, -1, lang_recode)
  
  #code any missing values 
  lang_recode <- ifelse(lang_recode==0, NA, lang_recode)
  
  return(lang_recode)
  
}

code_generation <- function(bpl, age, year, yr_usa) {
  
  # first, calculate age of entry into the US, NA for all non-migrants
  age_usa <- age-yr_usa
  # check
  #tapply(age_usa, bpl>1, mean)
  #summary(age_usa)
  # some of these responses are as negative as -5. -1 is expected because of
  # the crudeness of calendar year vs birthdays. Almost all of the values 
  # greater than -1 are for year of migration prior to 1940, which is top-coded
  # in the data, so I think those make sense as well. In those cases, we will
  # just replace with zero.
  age_usa <- ifelse(age_usa<0, 0, age_usa)
  
  # now we can code our generations. All native-borns are 2nd+.
  generation <- case_when(
    is.na(bpl) ~ NA_character_,
    bpl==1 ~ "2nd+",
    age_usa<6 ~ "1.75",
    age_usa<13 ~ "1.5",
    age_usa<18 ~ "1.25",
    !is.na(age_usa) ~ "1st"
  )
  
  generation <- factor(generation,
                       levels=c("1st","1.25","1.5","1.75","2nd+"))
    
  # checks
  #summary(generation)
  #table(bpl>1, generation, exclude=NULL)
  #tapply(age_usa, generation, min)
  #tapply(age_usa, generation, max)

  return(generation)
}

```


# Read in the data

The data are ACS data from 2010-2019, extracted via IPUMS. Below, I show all variables and their position in the files. 

```
  Variable                         Columns        Len   2010    2011    2012    2013    2014    2015    2016    2017    2018    2019    
  YEAR                         H   1-4            4     X       X       X       X       X       X       X       X       X       X       
  SAMPLE                       H   5-10           6     X       X       X       X       X       X       X       X       X       X       
  SERIAL                       H  11-18           8     X       X       X       X       X       X       X       X       X       X       
  CBSERIAL                     H  19-31          13     X       X       X       X       X       X       X       X       X       X       
  HHWT                         H  32-41          10     X       X       X       X       X       X       X       X       X       X       
  CLUSTER                      H  42-54          13     X       X       X       X       X       X       X       X       X       X       
  STATEFIP                     H  55-56           2     X       X       X       X       X       X       X       X       X       X       
  COUNTYFIP                    H  57-59           3     X       X       X       X       X       X       X       X       X       X       
  PUMA                         H  60-64           5     X       X       X       X       X       X       X       X       X       X       
  MET2013                      H  65-69           5     X       X       X       X       X       X       X       X       X       X       
  STRATA                       H  70-81          12     X       X       X       X       X       X       X       X       X       X       
  GQ                           H  82              1     X       X       X       X       X       X       X       X       X       X       
  PERNUM                       P  83-86           4     X       X       X       X       X       X       X       X       X       X       
  PERWT                        P  87-96          10     X       X       X       X       X       X       X       X       X       X       
  SEX                          P  97              1     X       X       X       X       X       X       X       X       X       X       
  AGE                          P  98-100          3     X       X       X       X       X       X       X       X       X       X       
  MARST                        P 101              1     X       X       X       X       X       X       X       X       X       X       
  MARRNO                       P 102              1     X       X       X       X       X       X       X       X       X       X       
  YRMARR                       P 103-106          4     X       X       X       X       X       X       X       X       X       X       
  RACE                         P 107              1     X       X       X       X       X       X       X       X       X       X       
  RACED                        P 108-110          3     X       X       X       X       X       X       X       X       X       X       
  HISPAN                       P 111              1     X       X       X       X       X       X       X       X       X       X       
  HISPAND                      P 112-114          3     X       X       X       X       X       X       X       X       X       X       
  BPL                          P 115-117          3     X       X       X       X       X       X       X       X       X       X       
  BPLD                         P 118-122          5     X       X       X       X       X       X       X       X       X       X       
  YRIMMIG                      P 123-126          4     X       X       X       X       X       X       X       X       X       X       
  LANGUAGE                     P 127-128          2     X       X       X       X       X       X       X       X       X       X       
  LANGUAGED                    P 129-132          4     X       X       X       X       X       X       X       X       X       X       
  EDUC                         P 133-134          2     X       X       X       X       X       X       X       X       X       X       
  EDUCD                        P 135-137          3     X       X       X       X       X       X       X       X       X       X       
  PERNUM_SP                    P 138-141          4     X       X       X       X       X       X       X       X       X       X       
  SEX_SP                       P 142              1     X       X       X       X       X       X       X       X       X       X       
  AGE_SP                       P 143-145          3     X       X       X       X       X       X       X       X       X       X       
  RACED_SP                     P 146-148          3     X       X       X       X       X       X       X       X       X       X       
  HISPAND_SP                   P 149-151          3     X       X       X       X       X       X       X       X       X       X       
  BPLD_SP                      P 152-156          5     X       X       X       X       X       X       X       X       X       X       
  YRIMMIG_SP                   P 157-160          4     X       X       X       X       X       X       X       X       X       X       
  LANGUAGED_SP                 P 161-164          4     X       X       X       X       X       X       X       X       X       X       
  EDUCD_SP                     P 165-167          3     X       X       X       X       X       X       X       X       X       X       
```

Now, I am ready to read the data in. Because the dataset is very large, the data are currently stored on Google Drive and accessed using the `googledrive` library. A local copy is downloaded, read in, and then deleted.

```{r}
#| label: read-data

# where the downloaded data will live (temporarily)
file_path <- here("data","data_raw","acs.dat.gz")

# download the data file
drive_download(as_id("15jz02cevyTvLvGoyivrhQ5AU_lN8Z6Xu"), path=file_path)

acs <- read_fwf(file_path,
                col_positions = fwf_cols(
                  YEAR = c(1, 4),
                  SERIAL = c(11, 18),
                  HHWT = c(32, 41),
                  STATEFIP = c(55, 56),
                  COUNTYFIP = c(57, 59),
                  PUMA = c(60, 64),
                  MET2013 = c(65, 69),
                  PERNUM = c(83, 86),
                  SEX = 97,
                  AGE = c(98, 100),
                  MARST = 101,
                  MARRNO = 102,
                  YRMARR = c(103, 106),
                  RACED = c(108, 110),
                  HISPAND = c(112, 114),
                  BPLD = c(118, 122),
                  YRIMMIG = c(123, 126),
                  LANGUAGED = c(129, 132),
                  EDUCD = c(135, 137),
                  PERNUM_SP = c(138, 141),
                  SEX_SP = 142,
                  AGE_SP = c(143, 145),
                  RACED_SP = c(146, 148),
                  HISPAND_SP = c(149, 151),
                  BPLD_SP = c(152, 156),
                  YRIMMIG_SP = c(157, 160),
                  LANGUAGED_SP = c(161, 164),
                  EDUCD_SP = c(165, 167)
                ),
                col_types = cols(.default = "i", HHWT="d"), 
                progress = FALSE)

# now that the data are loaded, delete
file.remove(file_path)
```

# Code variables

```{r}
#| label: county-met-correspondence
table(acs$COUNTYFIP != 0, acs$MET2013 != 0)
```

The table above shows the cases where county and/or metro area are identifiable in the full data. We have considerably more cases where metro area is identifiable than county is identifiable.

I recode, create, and clean all of the variables that I need in one `mutate` call. Embedded comments should provide more details. I will check my coding below. 

```{r}
#| label: code-variables
acs <- acs |> 
  mutate(
    ## unique ids for each respondent ##
    id = SERIAL*1000000+PERNUM*10000+YEAR,
    id_sp = ifelse(is.na(PERNUM_SP),NA,
                    SERIAL*1000000+PERNUM_SP*10000+YEAR),
    ## sex of respondent and spouse ##
    sex = ifelse(SEX==1, "Male", ifelse(SEX==2, "Female", NA)),
    sex_sp = ifelse(SEX_SP==1, "Male", ifelse(SEX_SP==2, "Female", NA)),
    ## age of respondent and spouse ##
    age=AGE,
    age_sp=AGE_SP,
    ## marital status of respondent ##
    mar_stat=factor(MARST, levels=1:6, 
                    labels=c("Married, spouse present", "Married, spouse absent",
                             "Separated","Divorced","Widowed","Never married")),
    ## race of respondent and spouse - see details in code_race function ##
    race = code_race(RACED, HISPAND),
    race_sp = code_race(RACED_SP, HISPAND_SP),
    ## education of respondent and spouse - see code_educ function for details ##
    educ = code_educ(EDUCD),
    educ_sp = code_educ(EDUCD_SP),
    ## language of respondent and spouse - see code_lang for details ##
    lang = code_language(LANGUAGED),
    lang_sp = code_language(LANGUAGED_SP),
    ## marriage market id ##
    # we do marriage market with a cascading logic. First, we check for 
    # met2013. If this is identifiable, then we assign the metro area. Second,
    # for cases without met2013, we look for county and if identiable, then
    # we assign it. Third, if we have neither metro area or county, we assign
    # PUMA
    mar_market = case_when(
      MET2013 != 0 ~ paste("M", MET2013, YEAR, sep = "."),
      COUNTYFIP != 0 ~ paste("C", STATEFIP, COUNTYFIP, YEAR, sep = "."),
      TRUE ~ paste("P", STATEFIP, PUMA, YEAR, sep = ".")
    ),
    # a simpler alternative would be to use state
    #mar_market = paste(STATEFIP, YEAR, sep=""),
    ## marriage duration ##
    dur_mar = ifelse(YRMARR==0, NA, YEAR - YRMARR),
    ## country of birth of respondent and spouse - see code_bpl for details ##
    bpl = code_bpl(BPLD),
    bpl_sp = code_bpl(BPLD_SP),
    ## Years in the USA - missing for natives ##
    yr_usa = ifelse(YRIMMIG==0, NA, YEAR-YRIMMIG),
    yr_usa_sp = ifelse(YRIMMIG_SP==0, NA, YEAR-YRIMMIG_SP),
    ## immigrant generation - see code_generation for details ##
    immig_gen = code_generation(bpl, age, YEAR, yr_usa),
    immig_gen_sp = code_generation(bpl_sp, age_sp, YEAR, yr_usa_sp)
  )
```

Ok, now I check to make sure all of my coding worked as expected. This is a long section because the output is often quite large. 

```{r}
#| label: check-yourself

options(max.print=10000)

# Do we have any duplicates in our ids?
sum(duplicated(acs$id))
sum(duplicated(na.omit(acs$id_sp)))

# check sex
table(acs$sex, acs$SEX, exclude=NULL)
table(acs$sex_sp, acs$SEX_SP, exclude=NULL)

# check mar_stat
table(acs$mar_stat, acs$MARST, exclude=NULL)

# check age
summary(acs$age)
summary(acs$age_sp)

# check educ
table(acs$EDUCD, acs$educ, exclude=NULL)
table(acs$EDUCD_SP, acs$educ_sp, exclude=NULL)

# check race
table(acs$RACED, acs$race, exclude=NULL)
table(acs$HISPAND, acs$race, exclude=NULL)
table(acs$RACED_SP, acs$race_sp, exclude=NULL)
table(acs$HISPAND_SP, acs$race_sp, exclude=NULL)

# check birthplace
summary(acs$bpl)
summary(acs$bpl_sp)

# check language
summary(acs$lang)
sum(acs$lang==-1)
summary(acs$lang_sp)
sum(acs$lang_sp==-1, na.rm=TRUE)

# check dur_mar
summary(acs$dur_mar)

# check immigrant generation
table(acs$bpl>1, acs$immig_gen, exclude=NULL)
table(acs$bpl_sp>1, acs$immig_gen_sp, exclude=NULL)

# check marriage market
acs |>
  mutate(mar_market_type = str_sub(mar_market, 1, 1)) |>
  group_by(mar_market_type) |>
  summarize(n = n()) |>
  mutate(percent = 100 * n/sum(n))

options(max.print=99999)
```

Everything is coming up green lights at the moment.

# Make restrictions

Now that I have coded and checked the ACS dataset, lets just restrict to the variables that I need to keep things tidy. I will also remove cases that are missing on `race` or `race_sp` because those are individuals who had a race outside of what I am considering here (other single or in combination and more than two races). I will also drop the relatively few cases that were missing birthplace. Dropping on spouse `race_sp` and `bpl_sp` has to first check to make sure its a valid case otherwise (given by a non-missing id).

```{r}
#| label: drop-missing-select-vars
acs <- acs |>
  filter(!is.na(race) & !is.na(bpl)) |>
  filter(is.na(id_sp) | (!is.na(race_sp) & !is.na(bpl_sp))) |>
  select(mar_market, mar_stat, dur_mar, 
         id, sex, age, race, educ, lang, bpl, immig_gen, yr_usa,
         id_sp, sex_sp, age_sp, race_sp, educ_sp, lang_sp, bpl_sp, immig_gen_sp,
         yr_usa_sp)
```

I also want to eliminate individuals from the analysis who:

* have been in the USA less than the marriage window.
* Made an interstate move in the last five years <!-- TODO: implement this -->
* Are currently married longer than the marriage window.
* Are married individuals in same-sex relationships
* Are cohabitors - these are identified by a valid spouse id but not married, spouse present on `mar_stat`

Therefore, the only remaining people in the dataset are heterosexual married couples married for five years or less and single individuals, all of whom have been in the same "marriage market" for the last five years.

```{r}
#| label: restrict-cases
acs <- acs |>
  filter((is.na(yr_usa) | yr_usa>years_mar) & 
           (is.na(yr_usa_sp) | yr_usa_sp>years_mar) &
           ((mar_stat!="Married, spouse present" & 
               mar_stat!="Married, spouse absent") | dur_mar<=years_mar) &
           !(!is.na(sex_sp) & sex==sex_sp) &
           !(mar_stat!="Married, spouse present" & !is.na(id_sp)))

# checks
summary(acs$yr_usa)
summary(acs$yr_usa_sp)
tapply(acs$dur_mar, acs$mar_stat, max)
table(acs$sex, acs$sex_sp, exclude=NULL)
acs |> 
  group_by(mar_stat, !is.na(id_sp)) |>
  summarize(n=n())
```

# Create marriage market data

Now, I am ready to create the union and male/female alternate datasets that I will feed into `fakeunion` to get my marriage market data.

```{r}
#| label: create-groups

# create actual union data
unions <- acs |>
  filter(sex=="Male" & sex_sp=="Female" & !is.na(id_sp) & 
           mar_stat=="Married, spouse present")

# check that they are all hetero
table(unions$sex, unions$sex_sp, exclude=NULL)

# check the marital status 
table(unions$mar_stat)

# check marriage duration
summary(unions$dur_mar)

# check years in the USA is past marriage duration
summary(unions$yr_usa)

# ok now limit it to only necessary variables and rename
unions <- unions |>
  select(mar_market, id, age, race, educ, lang, bpl, immig_gen, 
         id_sp, age_sp, race_sp, educ_sp, lang_sp, bpl_sp, immig_gen_sp) |>
  rename(idh=id, ageh=age, raceh=race, educh=educ, langh=lang, bplh=bpl, 
         immig_genh=immig_gen,
         idw=id_sp, agew=age_sp, racew=race_sp, educw=educ_sp, langw=lang_sp, 
         bplw=bpl_sp, immig_genw=immig_gen_sp) 

# create alternate partner data
female_alt <- acs |>
  filter(sex=="Female") |>
  select(mar_market, id, age, race, educ, lang, bpl, immig_gen) |>
  rename(idw=id, agew=age, racew=race, educw=educ, langw=lang, bplw=bpl,
         immig_genw=immig_gen)

male_alt <- acs |>
  filter(sex=="Male") |>
  select(mar_market, id, age, race, educ, lang, bpl, immig_gen) |>
  rename(idh=id, ageh=age, raceh=race, educh=educ, langh=lang, bplh=bpl,
         immig_genh=immig_gen)
```

Now, that I have these datasets, I can feed them into the `generateCouples` function to create my marriage market data. I use the replicate function to create multiple marriage markets so I can pool results across multiple random imputations of fake partners.

Note that the `generateCouples` data cannot handle tibbles properly so I am casting these back to vanilla data.frames and then re-tibblizing the end product. 

```{r}
#| label: create-fake-unions

# fakeunion does not handle tibbles well so convert to vanilla dfs
mar_markets <- replicate(n_samples,
                         generateCouples(n_fakes, as.data.frame(unions), 
                                         as.data.frame(male_alt), 
                                         as.data.frame(female_alt), 
                                         geo="mar_market", 
                                         verbose=FALSE),
                         simplify=FALSE)

mar_markets <- lapply(mar_markets, as_tibble)
```



Lets do a summary on the first one just to make sure it all looks good.

```{r}
#| label: check-mar-market-data
summary(mar_markets[[1]])
```

It should be all good to go.

I have also found that fitting the fullest model of multiracial-to-multiracial intermarriage is proving difficult and takes a long time. So, we are going to estimate this model using a reduced marriage market of just multiracial individuals. That model will only be different than a full model because the control variables will be estimated differently, but should be otherwise quite close. 

```{r}
#| label: create-fake-union-multi

unions_multi <- unions |>
  filter(str_detect(raceh, "-") & str_detect(racew, "-")) |>
  mutate(raceh=fct_drop(raceh), racew=fct_drop(racew))

male_alt_multi <- male_alt |>
  filter(str_detect(raceh, "-")) |>
  mutate(raceh=fct_drop(raceh))

female_alt_multi <- female_alt |>
  filter(str_detect(racew, "-")) |>
  mutate(racew=fct_drop(racew))

mar_markets_multi <- replicate(n_samples,
                         generateCouples(n_fakes, 
                                         as.data.frame(unions_multi), 
                                         as.data.frame(male_alt_multi), 
                                         as.data.frame(female_alt_multi), 
                                         geo="mar_market", 
                                         verbose=FALSE),
                         simplify=FALSE)

mar_markets_multi <- lapply(mar_markets_multi, as_tibble)

```

Check that we have no monoracial people here:

```{r}
summary(mar_markets_multi[[1]]$raceh)
summary(mar_markets_multi[[1]]$racew)
```

```{r}
#| label: save-data
save(unions, male_alt, female_alt,
     file = here("data", "data_constructed", "unions_alts.RData"))
save(mar_markets, mar_markets_multi, 
     file = here("data", "data_constructed", "markets.RData"))
```

```{r}
#| label: timestamp-end
timestamp()
```